{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02039e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.9.16\r\n"
     ]
    }
   ],
   "source": [
    "!python -V"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ad318c",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15b30a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib as plt\n",
    "import mlflow\n",
    "import pickle\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb47511f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from category_encoders import TargetEncoder\n",
    "\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10a6b1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connecting to the AWS S3\n",
    "os.environ[\"AWS_PROFILE\"] = \"default\" # fill in with your AWS profile. More info: https://docs.aws.amazon.com/sdk-for-java/latest/developer-guide/setup.html#setup-credentials\n",
    "\n",
    "TRACKING_SERVER_HOST = \"ec2-13-251-63-107.ap-southeast-1.compute.amazonaws.com\" # fill in with the public DNS of the EC2 instance\n",
    "mlflow.set_tracking_uri(f\"http://{TRACKING_SERVER_HOST}:5000\")\n",
    "\n",
    "# Set the new experiment\n",
    "print(f\"tracking URI: '{mlflow.get_tracking_uri()}'\")\n",
    "\n",
    "# Check the experiment\n",
    "mlflow.search_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d7146cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kaggle datasets download -d mchirico/montcoalert\n",
    "\n",
    "dataset_name = \"spotify-and-youtube\"\n",
    "!kaggle datasets download -d salvatorerastelli/{dataset_name}\n",
    "!mkdir data\n",
    "!cd data\n",
    "!mkdir {dataset_name}\n",
    "!unzip -o {dataset_name}.zip -d data/{dataset_name}/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df96ea85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file and check\n",
    "df = pd.read_csv(\"data/spotify-and-youtube/Spotify_Youtube.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73627506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the index to be starting from 1 not zero\n",
    "df = df.reset_index(drop=True)\n",
    "df.index = df.index + 1\n",
    "\n",
    "# show the table\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d12be06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename all the column to be nice to see\n",
    "df['Trending'] = df.shape[0] + 1 - df['Views'].rank()\n",
    "df = df.sort_values(by='Trending', ascending=True)\n",
    "\n",
    "# Drop some unnecessary file\n",
    "df = df.dropna()\n",
    "df = df.drop('Url_spotify', axis=1)\n",
    "df = df.drop('Uri', axis=1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d74d5c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only numerical columns\n",
    "numerical_columns = df.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "# Calculate correlation\n",
    "correlation = df[numerical_columns].corr()['Trending']\n",
    "print(correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1029f258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the file into training data and testing data\n",
    "split_number = int(len(df)/2)\n",
    "\n",
    "df_train = df[:split_number]\n",
    "df_val = df[split_number:]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ee690c",
   "metadata": {},
   "source": [
    "# Training Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e7b1d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up for features engineering\n",
    "\n",
    "categorical = ['Licensed']\n",
    "numerical = ['Views', 'Likes']\n",
    "\n",
    "dv = DictVectorizer()\n",
    "\n",
    "train_dicts = df_train[categorical + numerical].to_dict(orient='records')\n",
    "X_train = dv.fit_transform(train_dicts)\n",
    "\n",
    "val_dicts = df_val[categorical + numerical].to_dict(orient='records')\n",
    "X_val = dv.transform(val_dicts)\n",
    "\n",
    "target = 'Trending'\n",
    "y_train = df_train[target].values\n",
    "y_val = df_val[target].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1c9302f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the data using simple method\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lr.predict(X_val)\n",
    "\n",
    "mean_squared_error(y_val, y_pred, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "150b4962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the range to assess the quality of our result (using percentage)\n",
    "range = df['Trending'].max() - df['Trending'].min()\n",
    "print(range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c8a80a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Set the experiment. If the experiment does not exist, it will be created.\n",
    "mlflow.set_experiment(\"my-experiment-2\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "    \n",
    "    mlflow.set_tag(\"owner\", 'M Irfan')\n",
    "    \n",
    "    mlflow.log_param(\"train-data-path\", \"./data/{dataset_name}.csv\")\n",
    "    \n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = lr.predict(X_val)\n",
    "    rmse = mean_squared_error(y_val, y_pred, squared = False)\n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "    \n",
    "    mlflow.sklearn.log_model(lr, artifact_path=\"models\")\n",
    "    print(f\"default artifacts URI: '{mlflow.get_artifact_uri()}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa3db0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from hyperopt.pyll import scope\n",
    "\n",
    "from datetime import datetime\n",
    "import mlflow.xgboost\n",
    "import pickle\n",
    "import boto3\n",
    "import s3fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "51841e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the data\n",
    "\n",
    "train = xgb.DMatrix(X_train, label=y_train)\n",
    "valid = xgb.DMatrix(X_val, label=y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "432fa1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    fs = s3fs.S3FileSystem(anon=False)  # Add this line\n",
    "\n",
    "    os.environ[\"AWS_PROFILE\"] = \"default\"\n",
    "    TRACKING_SERVER_HOST = \"ec2-13-251-63-107.ap-southeast-1.compute.amazonaws.com\"\n",
    "    mlflow.set_tracking_uri(f\"http://{TRACKING_SERVER_HOST}:5000\")\n",
    "    \n",
    "    current_datetime = datetime.now().strftime('%Y-%m-%d_%H:%M:%S.%f')\n",
    "\n",
    "    with mlflow.start_run():\n",
    "        print(f\"default artifacts URI: '{mlflow.get_artifact_uri()}'\")\n",
    "        \n",
    "        mlflow.set_tag(\"model\", \"xgboost\")\n",
    "        mlflow.log_params(params)\n",
    "        booster = xgb.train(\n",
    "            params=params,\n",
    "            dtrain=train,\n",
    "            num_boost_round=1000,\n",
    "            evals=[(valid, 'validation')],\n",
    "            early_stopping_rounds=50\n",
    "        )\n",
    "        y_pred = booster.predict(valid)\n",
    "        rmse = mean_squared_error(y_val, y_pred, squared=False)\n",
    "        mlflow.log_metric(\"rmse\", rmse)\n",
    "        \n",
    "        error_percentage = rmse / range * 100\n",
    "        mlflow.log_metric(\"error_percentage\", error_percentage)\n",
    "\n",
    "        mlflow.xgboost.save_model(booster, f\"/tmp/models_mlflow-{current_datetime}\")\n",
    "\n",
    "        with open(f\"/tmp/preprocessor-{current_datetime}.pkl\", \"wb\") as f_out:\n",
    "            pickle.dump(dv, f_out)\n",
    "\n",
    "        fs.put(f\"/tmp/preprocessor-{current_datetime}.pkl\", f\"s3://mlflow-artifacts-remote-zoomcamp/mlruns/preprocessor-{current_datetime}.pkl\")\n",
    "        fs.put(f\"/tmp/models_mlflow-{current_datetime}\", f\"s3://mlflow-artifacts-remote-zoomcamp/mlruns/model-{current_datetime}.xgb\")\n",
    "\n",
    "        mlflow.log_artifact(f\"/tmp/preprocessor-{current_datetime}.pkl\", artifact_path=\"preprocessor\")\n",
    "        mlflow.log_artifact(f\"/tmp/models_mlflow-{current_datetime}\", artifact_path=\"models_mlflow\")\n",
    "\n",
    "        print(f\"default artifacts URI: '{mlflow.get_artifact_uri()}'\")\n",
    "\n",
    "    return {'loss': rmse, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c3b650e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = {\n",
    "    'max_depth': scope.int(hp.quniform('max_depth', 4, 200, 1)),\n",
    "    'learning_rate': hp.loguniform('learning_rate', -3, 0),\n",
    "    'reg_alpha': hp.loguniform('reg_alpha', -5, -1),\n",
    "    'reg_lambda': hp.loguniform('reg_lambda', -6, -1),\n",
    "    'min_child_weight': hp.loguniform('min_child_weight', -6, -3),\n",
    "    'objective': 'reg:squarederror',\n",
    "    'seed': 42,\n",
    "    'verbosity': 3\n",
    "}\n",
    "\n",
    "best_result = fmin(\n",
    "    fn=objective,\n",
    "    space=search_space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=3,\n",
    "    trials=Trials()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6d8b0fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test using the best result\n",
    "\n",
    "# Make sure AWS credentials are set properly\n",
    "# Either using environment variables or ~/.aws/credentials\n",
    "os.environ[\"AWS_PROFILE\"] = \"default\" # fill in with your AWS profile. More info: https://docs.aws.amazon.com/sdk-for-java/latest/developer-guide/setup.html#setup-credentials\n",
    "\n",
    "TRACKING_SERVER_HOST = \"ec2-13-251-63-107.ap-southeast-1.compute.amazonaws.com\" # fill in with the public DNS of the EC2 instance\n",
    "\n",
    "# create a connection to S3\n",
    "fs = s3fs.S3FileSystem()\n",
    "\n",
    "# use a local tracking server\n",
    "mlflow.set_tracking_uri(\"file:///tmp/mlruns\")\n",
    "\n",
    "with mlflow.start_run(experiment_id=\"0\"):\n",
    "    \n",
    "    train = xgb.DMatrix(X_train, label=y_train)\n",
    "    valid = xgb.DMatrix(X_val, label=y_val)\n",
    "\n",
    "    best_params = {\n",
    "        'learning_rate': 0.09585355369315604,\n",
    "        'max_depth': 30,\n",
    "        'min_child_weight': 1.060597050922164,\n",
    "        'objective': 'reg:squarederror',\n",
    "        'reg_alpha': 0.018060244040060163,\n",
    "        'reg_lambda': 0.011658731377413597,\n",
    "        'seed': 42\n",
    "    }\n",
    "\n",
    "    mlflow.log_params(best_params)\n",
    "\n",
    "    booster = xgb.train(\n",
    "        params=best_params,\n",
    "        dtrain=train,\n",
    "        num_boost_round=1000,\n",
    "        evals=[(valid, 'validation')],\n",
    "        early_stopping_rounds=50\n",
    "    )\n",
    "\n",
    "    y_pred = booster.predict(valid)\n",
    "    rmse = mean_squared_error(y_val, y_pred, squared=False)\n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "    \n",
    "    error_percentage = rmse / range * 100\n",
    "    mlflow.log_metric(\"error_percentage\", error_percentage)\n",
    "\n",
    "    # Save model locally\n",
    "    mlflow.xgboost.save_model(booster, \"/tmp/models_mlflow\")\n",
    "\n",
    "    # Save the preprocessor locally\n",
    "    with open(\"/tmp/preprocessor.pkl\", \"wb\") as f_out:\n",
    "        pickle.dump(dv, f_out)\n",
    "\n",
    "    # Upload model and preprocessor to S3\n",
    "    fs.put(\"/tmp/preprocessor.pkl\", \"s3://mlflow-artifacts-remote-zoomcamp/mlruns/preprocessor.pkl\")\n",
    "    fs.put(\"/tmp/models_mlflow\", \"s3://mlflow-artifacts-remote-zoomcamp/mlruns/model.xgb\")\n",
    "\n",
    "    # Log artifacts paths to mlflow\n",
    "    mlflow.log_artifact(\"/tmp/preprocessor2.pkl\", artifact_path=\"preprocessor\")\n",
    "    mlflow.log_artifact(\"/tmp/models_mlflow2\", artifact_path=\"models_mlflow\")\n",
    "    \n",
    "    \n",
    "    print(f\"default artifacts URI: '{mlflow.get_artifact_uri()}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9d4ea5",
   "metadata": {},
   "source": [
    "# Model Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "69cbb735",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "MLFLOW_TRACKING_URI = \"sqlite:///mlflow.db\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e279d96f",
   "metadata": {},
   "source": [
    "## Interacting with the MLflow tracking server¶\n",
    "The MlflowClient object allows us to interact with...\n",
    "\n",
    "an MLflow Tracking Server that creates and manages experiments and runs.\n",
    "an MLflow Registry Server that creates and manages registered models and model versions.\n",
    "To instantiate it we need to pass a tracking URI and/or a registry URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d5127e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MlflowClient(tracking_uri=MLFLOW_TRACKING_URI)\n",
    "\n",
    "client.list_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d30c2a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "for run in runs:\n",
    "    print(f\"run id: {run.info.run_id}, rmse: {run.data.metrics['rmse']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670bebd1",
   "metadata": {},
   "source": [
    "### Interacting with the Model Registry\n",
    "\n",
    "In this section We will use the `MlflowClient` instance to:\n",
    "\n",
    "1. Register a new version for the experiment `nyc-taxi-regressor`\n",
    "2. Retrieve the latests versions of the model `nyc-taxi-regressor` and check that a new version `4` was created.\n",
    "3. Transition the version `4` to \"Staging\" and adding annotations to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9cda7b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = \"b8904012c84343b5bf8ee72aa8f0f402\"\n",
    "model_uri = f\"runs:/{run_id}/model\"\n",
    "mlflow.register_model(model_uri=model_uri, name=\"nyc-taxi-regressor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bab05cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"nyc-taxi-regressor\"\n",
    "latest_versions = client.get_latest_versions(name=model_name)\n",
    "\n",
    "for version in latest_versions:\n",
    "    print(f\"version: {version.version}, stage: {version.current_stage}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bc709e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_version = 4\n",
    "new_stage = \"Staging\"\n",
    "client.transition_model_version_stage(\n",
    "    name=model_name,\n",
    "    version=model_version,\n",
    "    stage=new_stage,\n",
    "    archive_existing_versions=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ca012350",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "date = datetime.today().date()\n",
    "client.update_model_version(\n",
    "    name=model_name,\n",
    "    version=model_version,\n",
    "    description=f\"The model version {model_version} was transitioned to {new_stage} on {date}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0b8e4477",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time test_model(name=model_name, stage=\"Production\", X_test=X_test, y_test=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0837abea",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.transition_model_version_stage(\n",
    "    name=model_name,\n",
    "    version=4,\n",
    "    stage=\"Production\",\n",
    "    archive_existing_versions=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
